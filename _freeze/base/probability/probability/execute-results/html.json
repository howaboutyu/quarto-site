{
  "hash": "a22236ee1ce17acfbfa33e4b14b1182a",
  "result": {
    "markdown": "---\ntitle: Basic Probability\nformat: html\nreference-location: margin\nbibliography: ../../references.bib\nhtml-math-method: katex\neditor:\n  render-on-save: true\nexecute:\n  freeze: true\n---\n\n## Questions from @Bertsekas2000\n\n::: {.callout-tip collapse=\"false\"}\n# Axioms\nAdditivity axiom : for disjoint sets $P(A_1 ∪ A_2 ∪···) = P(A_1) + P(A_2) + ···$\n\nFor independence, we need $P(A\\cap B) = P(A)P(B)$\n:::\n::: {.border} \n**Example 1.11**\nA class consisting of 4 graduate and 12 undergraduate students\nis randomly divided into 4 groups of 4. What is the probability that each group\nincludes a graduate student? We interpret randomly to mean that given the assignment of some students to certain slots, any of the remaining students are equally\nlikely to be assigned to any of the remaining slots. \n:::\n\n\n::: {.callout-note collapse=\"true\"}\n# **Solution**\n\nIn the beginning, we have 16 different slots, where each group takes up 4 slots. Let $G$ be the event that every group has one grad student. \n$$\n\\begin{align}\nA_0 = \\text{\\{Grad student 1 is in different groups, but $P(A_0)=1$\\}}  \\nonumber \\\\\nA_1 = \\text{\\{Grad student 1 and 2 are in different groups\\}}  \\nonumber \\\\\nA_2 = \\text{\\{Grad student 1, 2 and 3 are in different groups\\}} \\nonumber \\\\\nA_3 = \\text{\\{Grad student 1, 2, 3, 4 are in different groups\\}} \\nonumber\n\\end{align}\n$$\n\nAfter grad student 1 has been picked only 15 people will be left, and since the available slots left are 3 we have 12 possible locations (3*4=12). Thus:\n\n\n$$\nP(A_1) = P(A_0 \\cap A_1)=P(A_0)P(A_1|A_0)=P(A_1|A_0)=12/15\n$$\n\nSimilarily:\n\n$$\nP(A_2) =P(A_1)P(A_2|A_1)=(12/15)*(2*4/14)=12*8/15*14\n$$\n$$\nP(A_3) = P(A_2)P(A_3|A_2)=P(A_2)*4/13=0.1406\n$$\n\nLet us see if this is really the case with a simulation\n\n::: {.cell execution_count=1}\n``` {.python .cell-code code-fold=\"true\"}\nimport numpy as np\nimport random\nfrom tqdm import tqdm\nvalid_array = []\nnum_sim = 1000 # NOTE: remember to set high for better results\n\nfor _ in range(num_sim):\n  student_id = np.arange(1, 17)\n\n  random.shuffle(student_id)\n\n  groups = [\n    student_id[0:4],\n    student_id[4:8],\n    student_id[8:12],\n    student_id[12:16],\n    ] \n\n  for g in groups:\n    num_grad_in_g = 0 \n    for g_id in [1,2,3,4]:\n      if g_id in g:\n        num_grad_in_g += 1\n    if num_grad_in_g > 1:\n      break\n    \n  if num_grad_in_g >1:\n    valid_array.append(0)\n  else: \n    valid_array.append(1)\n\nprint(f'Probability is {np.sum(valid_array)/float(num_sim)} after {num_sim} trials.')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nProbability is 0.13 after 1000 trials.\n```\n:::\n:::\n\n\n:::\n\n\n::: {.border} \n**Example 1.14.** Alice is taking a probability class and at the end of each week\nshe can be either up-to-date or she may have fallen behind. If she is up-to-date in\na given week, the probability that she will be up-to-date (or behind) in the next\nweek is 0.8 (or 0.2, respectively). If she is behind in a given week, the probability\nthat she will be up-to-date (or behind) in the next week is 0.6 (or 0.4, respectively).\nAlice is (by default) up-to-date when she starts the class. What is the probability\nthat she is up-to-date after three weeks?\n:::\n\n::: {.callout-note collapse=\"true\"}\n# **Solution**\n\nLet $U_i$ be the event that Alice is up-to-date at the end of week $i$ and $\\overline{U}_i$ be not up-to-date, the goal is the find $P(U_3)$. \n\nStarting with \n$P(U_2)=P(U_2\\cap U_1)\\bigcup P(U_2\\cap\\overline{U}_1)$ which becomes $P(U_2) = P(U_1)P(U_2|U_1)+ P(\\overline{U}_1)P(U_2|\\overline{U}_1)$. Since she starts the week up-to-date, then $P(U_1)=0.8, P(\\overline{U}_1) = 0.2$.  \n\n\nThus, $P(U_2) = 0.8 * 0.8 + 0.2 * 0.4=0.72$. \nSimilarily: \n$$\nP(\\overline{U}_2) = P(U_1)P(\\overline{U}_2|U_1)+ P(\\overline{U}_1)P(\\overline{U}_2|\\overline{U}_1) \\\\\n=0.8 * 0.2 + 0.2 * 0.6 = 0.28\n$$\n\nFinally, \n\n$$\n\\begin{align}\nP(U_3) &= P(U_2)P(U_3|U_2)+ P(\\overline{U}_2)P(U_3|\\overline{U}_2) \\\\\n&=0.72*0.8 + 0.28 * 0.4 \\\\\n&=0.688\n\\end{align}\n$$\n:::\n\n::: {.border} \n**Example 1.17.** Consider an experiment involving two successive rolls of a 4-sided\ndie in which all 16 possible outcomes are equally likely and have a probability of 1/16.\n\n Are the events $A = \\text{\\{maximum of the two rolls is 2\\}}, B = \\text{\\{minimum of the two rolls is 2}\\}$ independent?\n::: \n\n::: {.callout-note collapse=\"true\"}\n# **Solution** \n\nThey are not independent because $P(A) = 3/16, P(B) = 5/16, P(A\\cap B) = 1/16 \\neq 15/(16*16)$. \n\n:::\n::: {.border} \n**Example 1.22.** Network connectivity. A computer network connects two\nnodes A and B through intermediate nodes C, D, E, and F.\nFor every pair of directly connected nodes, say i and j, there is a given probability\n$p_{ij}$ that the link from $i$ to $j$ is up. We assume that link failures are independent of each other. What is the probability that there is a path connecting A and B in\nwhich all links are up?\n\n![](images/Example1.22.jpg)\n\n::: \n\n\n::: {.callout-note collapse=\"true\"}\n# **Solution** \n\n$$\n\\begin{align}\nP(l_1:= A\\rightarrow D \\rightarrow B) = 0.75 * 0.95 =0.7125\\\\\nP(l_2:=C\\rightarrow E \\rightarrow B) = 0.8 * 0.9 =0.72\\\\\nP(l_3:=C\\rightarrow F \\rightarrow B) = 0.95 * 0.85=0.8075 \\\\\n\\end{align} \n$$\n\nThe probability that $l_4: C\\rightarrow B$ has at least one successful path is : \n\n$$P(l_2 \\cap l_3)\\cup P(l_2 \\cap \\overline{l_3}) \\cup P(\\overline{l_2} \\cap l_3) = 0.9461$$ \n\n$$P(l_5 : A\\rightarrow l_4) = 0.9 * 0.9461  = 0.85149 $$\nFinally,\n$$P(l_f) = P(l_1 \\cap l_5)\\cup P(l_1 \\cap \\overline{l_5}) \\cup P(\\overline{l_1} \\cap l_5) $$ \n$$P(l_f) = 0.7125 * 0.85149 + 0.7125 * (1- 0.85149) + (1-0.7125 ) * 0.85149=0.9573$$ \n:::\n\n\n::: {.border}\n**Example 2.1.** Let $Y = |X|$ and let us apply the formula^[Suppose we have a transformation $Y=g(X)$. The PMF for Y is $p_Y(y) = \\sum_{\\{x| g(x) = y\\}} p_X(x)$] for the PMF\n$p_Y$ to the case where\n\n$$\np_X(x) = \n\\begin{cases}\n1/9, &\\text{if x is an integer in the range [−4, 4]} \\\\\n0,  &\\text{else}\n\\end{cases}\n$$\n\n\nThe possible values of $Y$ are $y = 0, 1, 2, 3, 4$.\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n# **Solution**\n$$\n\\begin{align}\np_Y(0)&= p_X(0) \\nonumber \\\\\np_Y(1)&= p_X(-1)  + p_X(1) \\nonumber \\\\\np_Y(2)&= p_X(-2)  + p_X(2) \\nonumber  \\\\\np_Y(3)&= p_X(-3)  + p_X(3)  \\nonumber \\\\\n\\end{align}\n$$\n\n\nThus the PMF of $Y$ is \n\n$$\np_Y(y) = \n\\begin{cases}\n1/9, &\\text{If $y=0$} \\\\\n2/9, &\\text{If $y=1,2,3,4$} \\\\\n0, &\\text{else} \\\\\n\\end{cases}\n$$\n\nThe mean ($\\bold{E}[X]=\\sum_x x p_X (x)$) is then\n\n$$\n\\bold{E}[Y]=0 * 1/9 + 2/9 + 2*2/9 + 3*2/9 + 4*2/9=20/9\n$$\n\nThe variance ($var(X) = \\bold{E}((X-\\bold{E}(X))^2)$), let $Z=(Y-\\bold{E}(Y))^2$\n$$\np_Z(z) = \n\\begin{cases}\n(20/9-1/9)^2, &\\text{If $y=0$} \\\\\n(20/9-2/9)^2, &\\text{If $y=1,2,3,4$} \\\\\n0, &\\text{else} \\\\\n\\end{cases}\n$$\n\nThus\n\n$$\nvar(Y) = (18/9)^2  +  2*(18/9)^2 +3*(18/9)^2 +4*(18/9)^2\n$$\n:::\n\n::: {.border}\n**Example 2.8.** Average Speed Versus Average Time. If the weather is good\n(which happens with probability 0.6), Alice walks the 2 miles to class at a speed of\nV = 5 miles per hour, and otherwise drives her motorcycle at a speed of V = 30\nmiles per hour. What is the mean of the time T to get to class?\n:::\n\n::: {.callout-note collapse=\"true\"}\n# **Solution**\n$$\np_T(t) = \n\\begin{cases}\n0.6 & \\text{if $t = 2/5$} \\\\\n0.4 & \\text{if $t = 2/30$} \\\\\n\\end{cases}\n$$\n\nThus, \n\n$$\nE[T] = 0.6*2/5 + 0.4*2/30\n$$\n\nBut using $E[V]$ to find $E[T]$ using $E[T] = E[1/V] =1/E[V]$ doesn't work. Because $1/x$ is not linear.\n:::\n\n::: {.border}\n\n**Example 2.11.** Professor May B. Right often has her facts wrong, and answers\neach of her students’ questions incorrectly with probability 1/4, independently of\nother questions. In each lecture, May is asked 0, 1, or 2 questions with an equal probability of 1/3. Let X and Y be the number of questions May is asked and the number of\nquestions she answers wrong in a given lecture, respectively. Construct the joint\nPMF $p_{X,Y} (x, y)$\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n# **Solution**\n\n\nThe PMF $p_{X,Y} (x, y)$ - defined as $p_{X,Y} (x, y) = P(X=x, Y=y)$ - can be found by using the multiplication rule; $p_{X,Y}(x,y) = p_X(x)p_{Y|X}(y|x)$:\n\n|     \t|     \t|      \t|      \t|\n|-----\t|-----\t|------\t|------\t|\n| y=2 \t| 0   \t| 0    \t| 1/48 \t|\n| y=1 \t| 0   \t| 1/12 \t| 6/48 \t|\n| y=0 \t| 1/3   \t| 3/12 \t| 9/48 \t|\n|     \t| x=0 \t| x=1  \t| x=2  \t|\n:::\n\n\n::: {.border}\n**Example 2.12.** Consider four independent rolls of a 6-sided die. Let $X$ be the\nnumber of 1’s and let $Y$ be the number of 2’s obtained. What is the joint PMF of\n$X$ and $Y$ ?\n:::\n\n::: {.callout-note collapse=\"true\"}\n# **Solution**\n\nThe PMF of $X$ is:\n\n$$\np_X(x) =  \\dbinom{4}{x} \\left( \\frac{1}{6} \\right) ^x \\left( \\frac{5}{6}\\right) ^ {4-x}\n$$\n\n$Y$  is the number 2's, so conditioned on $x$  (the number of 1's), the possible choices are limited to $2,3,4,5,6$, and the number of 2's required becomes $4-x$\n$$\np_{Y|X}(y|x) =  \\dbinom{4-x}{y} \\left( \\frac{1}{5} \\right) ^y \\left( \\frac{4}{5}\\right) ^ {4-x-y}\n$$\n\nThus:\n\n$$\np_{X,Y}(x,y) = \n\\begin{cases}\n \\dbinom{4}{x} \\left( \\frac{1}{6} \\right) ^x \\left( \\frac{5}{6}\\right) ^ {4-x}  \\dbinom{4-x}{y} \\left( \\frac{1}{5} \\right) ^y \\left( \\frac{4}{5}\\right) ^ {4-x-y} &\\text{If $0\\leq x+y\\leq 4$} \\\\\n 0 &\\text{else}\n\\end{cases}\n$$\n:::\n\n::: {.border}\n**Example 2.13.** Consider a transmitter that is sending messages over a computer\nnetwork. \n:::\n\n::: {.callout-note collapse=\"true\"}\n# Example\nLet us have two random variables:\n\n$$\nX = \\text{the travel time of the message}, Y=\\text{the length of the message}\n$$\n\nWe are given:\n\n* The length of a message can take two possible values: $y = 10^2$\nbytes with probability 5/6, and $y = 10^4$ bytes with probability 1/6. This is the PMF of $X$ - $p_X(x)$.\n* We know that the travel time of the message depends on the length, i.e. $p_{X|Y}(x|y)$. In particular,\n  travel time is $10^{−4}Y$ secs with probability 1/2, $10^{−3}Y$ secs with probability 1/3, and $10^{−2}Y$ secs with probability 1/6.\n\nSo, \n$$\np_Y(y) = \n\\begin{cases}\n5/6 & \\text{if } y=10^2 \\\\\n1/6 & \\text{if } y=10^4\n\\end{cases}\n$$\n\n$$\np_{X|Y}(x|y=10^2) =\n\\begin{cases}\n 1/2  &\\text{if }  x=10^{-2} \\\\\n 1/3  &\\text{if }  x=10^{-1} \\\\\n 1/6  &\\text{if }  x=1 \\\\\n\\end{cases}\n$$\n\n$$\np_{X|Y}(x|y=10^4) =\n\\begin{cases}\n 1/2  &\\text{if }  x=1 \\\\\n 1/3  &\\text{if }  x=10 \\\\\n 1/6  &\\text{if }  x=10^2 \\\\\n\\end{cases}\n$$\n\nUsing the **Total probability theorem**-$p_X(x) =\\sum_y p_{X|Y}(x|y) * p_Y(y)$\n\n$$\n\\begin{align}\np_X(x) &= \\sum_{y=\\{10^2, 10^4\\}} p_{X|Y}(x|y) * p_Y(y) \\nonumber \\\\ \n&=  p_{X|Y}(x|y=10^2)  p_Y(y=10^2) + p_{X|Y}(x|y=10^4)  p_Y(y=10^4) \\nonumber\n\\end{align}\n$$\n\nFor instance, to find the probability of the travel time of the message being 1 sec, \n\n$$\np_X(x=1) = 1/6 * 5*6 + 1/2*1/6   \n$$\n\n*Very cool!*\n:::\n\n\n::: {.border}\n**Example 2.15.** *Mean and Variance of the Geometric Random Variable.*\n\nYou write a software program over and over, and each time there is a probability $p$\nthat it works correctly, independently from previous attempts. What is the mean\nand variance of $X$, the number of tries until the program works correctly?\n:::\n\n::: {.callout-note collapse=\"true\"}\n# **Solution**\n\n$X$ is a geometric random variable with PMF:\n$$\np_X(k) = (1-p)^{k-1} p  \\quad k = 1,2,3,\\dots\n$$\n\nThe mean is \n$$\nE[X] = \\sum_{k=1}^{\\infty} k   (1-p)^{k-1} p\n$$\n\nThe variance is  $var(X) = E((X-E(X))^2) = \\sum_{k=1}^{\\infty} (k - E(X))(1-p)^{k-1} p$.\n\nLet's define $P(A_1 = \\{X=1\\})$ and $P(A_2 = \\{X>1\\})$ - meaning the first time works and the first time didn't work, respectively.\n\nThe conditional expectation of $A_1$:\n$$\n\\begin{align}\nE[X| A_1 = \\{X=1\\}] &= 1 \n\\end{align}\n$$ \n\n\nThe conditional expectation of $A_2$:\n$$\n\\begin{align}\nE[X| A_2 = \\{X>1\\}] &= 1 + E[X] \n\\end{align}\n$$ \n\nThis is because the first try was a failure. Thus, using the **Total Expectation Theorem** - $E[X] = \\sum_y p_Y(y) E[X|Y=y]$ - we have:\n\n$$\n\\begin{align}\nE[X] &= P(X=1) E[X|X=1] + P(X>1) E[X|X>1] \\nonumber \\\\\n&= p + (1-p)(1+E[X]) = 1/p\n\\end{align}\n$$\n\n::: \n\n\n::: {.border}\n**Example 3.5.** The time until a small meteorite first lands anywhere in the Sahara\ndesert is modeled as an exponential random variable with a mean of 10 days. The\ntime is currently midnight. What is the probability that a meteorite first lands\nsome time between 6am and 6pm of the first day? And, on any day?\n:::\n\n::: {.callout-note collapse=\"false\"}\n# **Solution**\n\nThe exponential random variable has the PDF of the form:\n\n$$\nf_X(x) = \n\\begin{cases}\n\\lambda e ^{-\\lambda x} &\\quad \\text{if x > 0} \\\\\n0 &\\quad \\text{else}\n\\end{cases}\n$$\n\n\nSince the mean is $E[X] = 1/\\lambda$, then $\\lambda = 1/10$. The unit is in days, so 6 am to 6 pm is $1/4$ and $3/4$, respectively.\n\n$$\nP(1/4 < X < 3/4 ) = \\int_{1/4}^{3/4} \\lambda e ^{-\\lambda x} dx \n$$\n\nFor any day, we need to sum all of the probabilities for each day.\n\n$$\nP(\\text{6am-6pm}) = \\sum_{k=1}^{\\infty} P(k - 3/4 < X < k-1/4) \n$$\n\n:::\n::: {.border}\n**Example 3.6.** The Geometric and Exponential CDFs.\n:::\n\n::: {.callout-note }\n# Comparing geometric and exponential CDF\n\nThe CDF is defined as $F(x) = P(X\\leq x) \\quad \\forall x$\n$$\nF^{geo}(n) = \\sum_{k=1}^{n}p(1-p) ^{k-1} \n$$\n\nUsing $r = (1-p)$, the geometric sum is then\n\n$$\nF^{geo}(n) = p \\frac{1-(1-p)^n}{1-(1-p)} = 1-(1-p)^n\n$$\n\n\nFor exponential,\n\n$$\n\\begin{align}\nF^{exp}(x) &= \\int_{-\\infty}^{x}  \\lambda e^{-\\lambda z} dz \\\\\n          &=1 - e ^{-\\lambda x} \\quad \\forall x >0\n\\end{align}\n$$\n\n::: {.cell execution_count=2}\n``` {.python .cell-code code-fold=\"true\"}\nimport numpy as np\nimport matplotlib.pyplot as plt\nn = np.linspace(0., 50., 100)\nF_geo = lambda p, n: 1 - np.power((1-p),np.floor(n))\nF_exp = lambda l, x: 1 - np.exp(-l* x)\n\np = 0.11\nl = 1/p\nf_geo = F_geo(p, n)\nsigma = -np.log(1 - p)/l\nf_lambda = F_exp(l, n*sigma)\nplt.plot(n, f_geo, n, f_lambda)\n_ = plt.title('$F_{geo}(\\sigma n)$ vs $F_{exp}(n)$ where $\\sigma = -ln(1-p)/\\lambda$')\n```\n\n::: {.cell-output .cell-output-display}\n![](probability_files/figure-html/cell-3-output-1.png){width=571 height=432}\n:::\n:::\n\n\n:::\n\n## Cool simulations\n\n### Monte Hall simulation\n\n::: {.cell execution_count=3}\n``` {.python .cell-code code-fold=\"true\"}\nimport numpy as np\nimport random\nfrom tqdm import tqdm\n\ndef mt(switch):\n  win_array = []\n  for _ in range(num_sim):\n    # 1 - car\n    prizes = np.arange(1, 4)\n    random.shuffle(prizes)\n\n    pick_id = np.random.randint(0, 3)\n    car_id,  = np.where(prizes == 1) \n\n    allowed = [0,1,2]\n    allowed.remove(pick_id)\n    host_allowed = allowed.copy()\n\n    if prizes[pick_id] != 1:\n      host_allowed.remove(car_id[0])\n\n    allowed.remove(host_allowed[0])\n\n    if switch:\n      if prizes[allowed[0]] == 1: \n        win_array.append(1) \n      else:\n        win_array.append(0)\n    else:\n      if prizes[pick_id] == 1: \n        win_array.append(1) \n      else:\n        win_array.append(0)\n  return np.sum(win_array)/float(num_sim)\n\nprint(f'After {num_sim} games')\nprint(f'Probability of winning the car with switching is {mt(1)} ')\nprint(f'Probability of winning the car without switching is {mt(0)} ')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAfter 1000 games\nProbability of winning the car with switching is 0.66 \nProbability of winning the car without switching is 0.342 \n```\n:::\n:::\n\n\n",
    "supporting": [
      "probability_files"
    ],
    "filters": [],
    "includes": {}
  }
}