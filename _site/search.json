[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Hi, I’m David Yu, a machine learning engineer. I’m passionate about using machine learning to solve problems and I like to make things. In my spare time, I enjoy riding motorcycles, travelling and playing the guitar.\n\n\nUniversity of Auckland | New Zealand Master of Engineering | 2016 - 2017\nUniversity of Auckland | New Zealand Bachelors of Engineering (Hon) | 2012 - 2015\n\n\n\nImagr Ltd | Machine Learning Engineer | September 2018 - September 2022\nAuckland Bioengineering Institute | Research Assistant | Mar 2017 – Aug 2018"
  },
  {
    "objectID": "base/probability/probability.html",
    "href": "base/probability/probability.html",
    "title": "Basic Probability",
    "section": "",
    "text": "Axioms\n\n\n\n\n\nAdditivity axiom : for disjoint sets P(A_1 ∪ A_2 ∪···) = P(A_1) + P(A_2) + ···\nFor independence, we need P(A\\cap B) = P(A)P(B)\n\n\n\n\nExample 1.11 A class consisting of 4 graduate and 12 undergraduate students is randomly divided into 4 groups of 4. What is the probability that each group includes a graduate student? We interpret randomly to mean that given the assignment of some students to certain slots, any of the remaining students are equally likely to be assigned to any of the remaining slots.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIn the beginning, we have 16 different slots, where each group takes up 4 slots. Let G be the event that every group has one grad student. \n\\begin{align}\nA_0 = \\text{\\{Grad student 1 is in different groups, but $P(A_0)=1$\\}}  \\nonumber \\\\\nA_1 = \\text{\\{Grad student 1 and 2 are in different groups\\}}  \\nonumber \\\\\nA_2 = \\text{\\{Grad student 1, 2 and 3 are in different groups\\}} \\nonumber \\\\\nA_3 = \\text{\\{Grad student 1, 2, 3, 4 are in different groups\\}} \\nonumber\n\\end{align}\n\nAfter grad student 1 has been picked only 15 people will be left, and since the available slots left are 3 we have 12 possible locations (3*4=12). Thus:\n\nP(A_1) = P(A_0 \\cap A_1)=P(A_0)P(A_1|A_0)=P(A_1|A_0)=12/15\n\nSimilarily:\n\nP(A_2) =P(A_1)P(A_2|A_1)=(12/15)*(2*4/14)=12*8/15*14\n \nP(A_3) = P(A_2)P(A_3|A_2)=P(A_2)*4/13=0.1406\n\nLet us see if this is really the case with a simulation\n\n\nCode\nimport numpy as np\nimport random\nfrom tqdm import tqdm\nvalid_array = []\nnum_sim = 1000 # NOTE: remember to set high for better results\n\nfor _ in range(num_sim):\n  student_id = np.arange(1, 17)\n\n  random.shuffle(student_id)\n\n  groups = [\n    student_id[0:4],\n    student_id[4:8],\n    student_id[8:12],\n    student_id[12:16],\n    ] \n\n  for g in groups:\n    num_grad_in_g = 0 \n    for g_id in [1,2,3,4]:\n      if g_id in g:\n        num_grad_in_g += 1\n    if num_grad_in_g > 1:\n      break\n    \n  if num_grad_in_g >1:\n    valid_array.append(0)\n  else: \n    valid_array.append(1)\n\nprint(f'Probability is {np.sum(valid_array)/float(num_sim)} after {num_sim} trials.')\n\n\nProbability is 0.144 after 1000 trials.\n\n\n\n\n\n\nExample 1.14. Alice is taking a probability class and at the end of each week she can be either up-to-date or she may have fallen behind. If she is up-to-date in a given week, the probability that she will be up-to-date (or behind) in the next week is 0.8 (or 0.2, respectively). If she is behind in a given week, the probability that she will be up-to-date (or behind) in the next week is 0.6 (or 0.4, respectively). Alice is (by default) up-to-date when she starts the class. What is the probability that she is up-to-date after three weeks?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet U_i be the event that Alice is up-to-date at the end of week i and \\overline{U}_i be not up-to-date, the goal is the find P(U_3).\nStarting with P(U_2)=P(U_2\\cap U_1)\\bigcup P(U_2\\cap\\overline{U}_1) which becomes P(U_2) = P(U_1)P(U_2|U_1)+ P(\\overline{U}_1)P(U_2|\\overline{U}_1). Since she starts the week up-to-date, then P(U_1)=0.8, P(\\overline{U}_1) = 0.2.\nThus, P(U_2) = 0.8 * 0.8 + 0.2 * 0.4=0.72. Similarily: \nP(\\overline{U}_2) = P(U_1)P(\\overline{U}_2|U_1)+ P(\\overline{U}_1)P(\\overline{U}_2|\\overline{U}_1) \\\\\n=0.8 * 0.2 + 0.2 * 0.6 = 0.28\n\nFinally,\n\n\\begin{align}\nP(U_3) &= P(U_2)P(U_3|U_2)+ P(\\overline{U}_2)P(U_3|\\overline{U}_2) \\\\\n&=0.72*0.8 + 0.28 * 0.4 \\\\\n&=0.688\n\\end{align}\n\n\n\n\n\nExample 1.17. Consider an experiment involving two successive rolls of a 4-sided die in which all 16 possible outcomes are equally likely and have a probability of 1/16.\nAre the events A = \\text{\\{maximum of the two rolls is 2\\}}, B = \\text{\\{minimum of the two rolls is 2}\\} independent?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThey are not independent because P(A) = 3/16, P(B) = 5/16, P(A\\cap B) = 1/16 \\neq 15/(16*16).\n\n\n\n\nExample 1.22. Network connectivity. A computer network connects two nodes A and B through intermediate nodes C, D, E, and F. For every pair of directly connected nodes, say i and j, there is a given probability p_{ij} that the link from i to j is up. We assume that link failures are independent of each other. What is the probability that there is a path connecting A and B in which all links are up?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\\begin{align}\nP(l_1:= A\\rightarrow D \\rightarrow B) = 0.75 * 0.95 =0.7125\\\\\nP(l_2:=C\\rightarrow E \\rightarrow B) = 0.8 * 0.9 =0.72\\\\\nP(l_3:=C\\rightarrow F \\rightarrow B) = 0.95 * 0.85=0.8075 \\\\\n\\end{align}\n\nThe probability that l_4: C\\rightarrow B has at least one successful path is :\nP(l_2 \\cap l_3)\\cup P(l_2 \\cap \\overline{l_3}) \\cup P(\\overline{l_2} \\cap l_3) = 0.9461\nP(l_5 : A\\rightarrow l_4) = 0.9 * 0.9461  = 0.85149  Finally, P(l_f) = P(l_1 \\cap l_5)\\cup P(l_1 \\cap \\overline{l_5}) \\cup P(\\overline{l_1} \\cap l_5)  P(l_f) = 0.7125 * 0.85149 + 0.7125 * (1- 0.85149) + (1-0.7125 ) * 0.85149=0.9573\n\n\n\n\nExample 2.1. Let Y = |X| and let us apply the formula1 for the PMF p_Y to the case where1 Suppose we have a transformation Y=g(X). The PMF for Y is p_Y(y) = \\sum_{\\{x| g(x) = y\\}} p_X(x)\n\np_X(x) =\n\\begin{cases}\n1/9, &\\text{if x is an integer in the range [−4, 4]} \\\\\n0,  &\\text{else}\n\\end{cases}\n\nThe possible values of Y are y = 0, 1, 2, 3, 4.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\\begin{align}\np_Y(0)&= p_X(0) \\nonumber \\\\\np_Y(1)&= p_X(-1)  + p_X(1) \\nonumber \\\\\np_Y(2)&= p_X(-2)  + p_X(2) \\nonumber  \\\\\np_Y(3)&= p_X(-3)  + p_X(3)  \\nonumber \\\\\n\\end{align}\n\nThus the PMF of Y is\n\np_Y(y) =\n\\begin{cases}\n1/9, &\\text{If $y=0$} \\\\\n2/9, &\\text{If $y=1,2,3,4$} \\\\\n0, &\\text{else} \\\\\n\\end{cases}\n\nThe mean (\\bold{E}[X]=\\sum_x x p_X (x)) is then\n\n\\bold{E}[Y]=0 * 1/9 + 2/9 + 2*2/9 + 3*2/9 + 4*2/9=20/9\n\nThe variance (var(X) = \\bold{E}((X-\\bold{E}(X))^2)), let Z=(Y-\\bold{E}(Y))^2 \np_Z(z) =\n\\begin{cases}\n(20/9-1/9)^2, &\\text{If $y=0$} \\\\\n(20/9-2/9)^2, &\\text{If $y=1,2,3,4$} \\\\\n0, &\\text{else} \\\\\n\\end{cases}\n\nThus\n\nvar(Y) = (18/9)^2  +  2*(18/9)^2 +3*(18/9)^2 +4*(18/9)^2\n\n\n\n\n\nExample 2.8. Average Speed Versus Average Time. If the weather is good (which happens with probability 0.6), Alice walks the 2 miles to class at a speed of V = 5 miles per hour, and otherwise drives her motorcycle at a speed of V = 30 miles per hour. What is the mean of the time T to get to class?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\np_T(t) =\n\\begin{cases}\n0.6 & \\text{if $t = 2/5$} \\\\\n0.4 & \\text{if $t = 2/30$} \\\\\n\\end{cases}\n\nThus,\n\nE[T] = 0.6*2/5 + 0.4*2/30\n\nBut using E[V] to find E[T] using E[T] = E[1/V] =1/E[V] doesn’t work. Because 1/x is not linear.\n\n\n\n\nExample 2.11. Professor May B. Right often has her facts wrong, and answers each of her students’ questions incorrectly with probability 1/4, independently of other questions. In each lecture, May is asked 0, 1, or 2 questions with an equal probability of 1/3. Let X and Y be the number of questions May is asked and the number of questions she answers wrong in a given lecture, respectively. Construct the joint PMF p_{X,Y} (x, y)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe PMF p_{X,Y} (x, y) - defined as p_{X,Y} (x, y) = P(X=x, Y=y) - can be found by using the multiplication rule; p_{X,Y}(x,y) = p_X(x)p_{Y|X}(y|x):\n\n\n\ny=2\n0\n0\n1/48\n\n\ny=1\n0\n1/12\n6/48\n\n\ny=0\n1/3\n3/12\n9/48\n\n\n\nx=0\nx=1\nx=2\n\n\n\n\n\n\n\nExample 2.12. Consider four independent rolls of a 6-sided die. Let X be the number of 1’s and let Y be the number of 2’s obtained. What is the joint PMF of X and Y ?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe PMF of X is:\n\np_X(x) =  \\dbinom{4}{x} \\left( \\frac{1}{6} \\right) ^x \\left( \\frac{5}{6}\\right) ^ {4-x}\n\nY is the number 2’s, so conditioned on x (the number of 1’s), the possible choices are limited to 2,3,4,5,6, and the number of 2’s required becomes 4-x \np_{Y|X}(y|x) =  \\dbinom{4-x}{y} \\left( \\frac{1}{5} \\right) ^y \\left( \\frac{4}{5}\\right) ^ {4-x-y}\n\nThus:\n\np_{X,Y}(x,y) =\n\\begin{cases}\n\\dbinom{4}{x} \\left( \\frac{1}{6} \\right) ^x \\left( \\frac{5}{6}\\right) ^ {4-x}  \\dbinom{4-x}{y} \\left( \\frac{1}{5} \\right) ^y \\left( \\frac{4}{5}\\right) ^ {4-x-y} &\\text{If $0\\leq x+y\\leq 4$} \\\\\n0 &\\text{else}\n\\end{cases}\n\n\n\n\n\nExample 2.13. Consider a transmitter that is sending messages over a computer network.\n\n\n\n\n\n\n\nExample\n\n\n\n\n\nLet us have two random variables:\n\nX = \\text{the travel time of the message}, Y=\\text{the length of the message}\n\nWe are given:\n\nThe length of a message can take two possible values: y = 10^2 bytes with probability 5/6, and y = 10^4 bytes with probability 1/6. This is the PMF of X - p_X(x).\nWe know that the travel time of the message depends on the length, i.e. p_{X|Y}(x|y). In particular, travel time is 10^{−4}Y secs with probability 1/2, 10^{−3}Y secs with probability 1/3, and 10^{−2}Y secs with probability 1/6.\n\nSo, \np_Y(y) =\n\\begin{cases}\n5/6 & \\text{if } y=10^2 \\\\\n1/6 & \\text{if } y=10^4\n\\end{cases}\n\n\np_{X|Y}(x|y=10^2) =\n\\begin{cases}\n1/2  &\\text{if }  x=10^{-2} \\\\\n1/3  &\\text{if }  x=10^{-1} \\\\\n1/6  &\\text{if }  x=1 \\\\\n\\end{cases}\n\n\np_{X|Y}(x|y=10^4) =\n\\begin{cases}\n1/2  &\\text{if }  x=1 \\\\\n1/3  &\\text{if }  x=10 \\\\\n1/6  &\\text{if }  x=10^2 \\\\\n\\end{cases}\n\nUsing the Total probability theorem-p_X(x) =\\sum_y p_{X|Y}(x|y) * p_Y(y)\n\n\\begin{align}\np_X(x) &= \\sum_{y=\\{10^2, 10^4\\}} p_{X|Y}(x|y) * p_Y(y) \\nonumber \\\\\n&=  p_{X|Y}(x|y=10^2)  p_Y(y=10^2) + p_{X|Y}(x|y=10^4)  p_Y(y=10^4) \\nonumber\n\\end{align}\n\nFor instance, to find the probability of the travel time of the message being 1 sec,\n\np_X(x=1) = 1/6 * 5*6 + 1/2*1/6   \n\nVery cool!\n\n\n\n\nExample 2.15. Mean and Variance of the Geometric Random Variable.\nYou write a software program over and over, and each time there is a probability p that it works correctly, independently from previous attempts. What is the mean and variance of X, the number of tries until the program works correctly?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nX is a geometric random variable with PMF: \np_X(k) = (1-p)^{k-1} p  \\quad k = 1,2,3,\\dots\n\nThe mean is \nE[X] = \\sum_{k=1}^{\\infty} k   (1-p)^{k-1} p\n\nThe variance is var(X) = E((X-E(X))^2) = \\sum_{k=1}^{\\infty} (k - E(X))(1-p)^{k-1} p.\nLet’s define P(A_1 = \\{X=1\\}) and P(A_2 = \\{X>1\\}) - meaning the first time works and the first time didn’t work, respectively.\nThe conditional expectation of A_1: \n\\begin{align}\nE[X| A_1 = \\{X=1\\}] &= 1\n\\end{align}\n\nThe conditional expectation of A_2: \n\\begin{align}\nE[X| A_2 = \\{X>1\\}] &= 1 + E[X]\n\\end{align}\n\nThis is because the first try was a failure. Thus, using the Total Expectation Theorem - E[X] = \\sum_y p_Y(y) E[X|Y=y] - we have:\n\n\\begin{align}\nE[X] &= P(X=1) E[X|X=1] + P(X>1) E[X|X>1] \\nonumber \\\\\n&= p + (1-p)(1+E[X]) = 1/p\n\\end{align}\n\n\n\n\n\nExample 3.5. The time until a small meteorite first lands anywhere in the Sahara desert is modeled as an exponential random variable with a mean of 10 days. The time is currently midnight. What is the probability that a meteorite first lands some time between 6am and 6pm of the first day? And, on any day?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe exponential random variable has the PDF of the form:\n\nf_X(x) =\n\\begin{cases}\n\\lambda e ^{-\\lambda x} &\\quad \\text{if x > 0} \\\\\n0 &\\quad \\text{else}\n\\end{cases}\n\nSince the mean is E[X] = 1/\\lambda, then \\lambda = 1/10. The unit is in days, so 6 am to 6 pm is 1/4 and 3/4, respectively.\n\nP(1/4 < X < 3/4 ) = \\int_{1/4}^{3/4} \\lambda e ^{-\\lambda x} dx\n\nFor any day, we need to sum all of the probabilities for each day.\n\nP(\\text{6am-6pm}) = \\sum_{k=1}^{\\infty} P(k - 3/4 < X < k-1/4)\n\n\n\n\n\nExample 3.6. The Geometric and Exponential CDFs.\n\n\n\n\n\n\n\nComparing geometric and exponential CDF\n\n\n\nThe CDF is defined as F(x) = P(X\\leq x) \\quad \\forall x \nF^{geo}(n) = \\sum_{k=1}^{n}p(1-p) ^{k-1}\n\nUsing r = (1-p), the geometric sum is then\n\nF^{geo}(n) = p \\frac{1-(1-p)^n}{1-(1-p)} = 1-(1-p)^n\n\nFor exponential,\n\n\\begin{align}\nF^{exp}(x) &= \\int_{-\\infty}^{x}  \\lambda e^{-\\lambda z} dz \\\\\n          &=1 - e ^{-\\lambda x} \\quad \\forall x >0\n\\end{align}\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nn = np.linspace(0., 50., 100)\nF_geo = lambda p, n: 1 - np.power((1-p),np.floor(n))\nF_exp = lambda l, x: 1 - np.exp(-l* x)\n\np = 0.11\nl = 1/p\nf_geo = F_geo(p, n)\nsigma = -np.log(1 - p)/l\nf_lambda = F_exp(l, n*sigma)\nplt.plot(n, f_geo, n, f_lambda)\n_ = plt.title('$F_{geo}(\\sigma n)$ vs $F_{exp}(n)$ where $\\sigma = -ln(1-p)/\\lambda$')"
  },
  {
    "objectID": "base/CompNeuro/cns.html",
    "href": "base/CompNeuro/cns.html",
    "title": "Computation neural science",
    "section": "",
    "text": "1a Code LIF neuron using the equation\nC_m \\frac{dV_m}{dt} = (E_L - V_m)/R_m + I_{app}   \nwith the condition \\quad V_m > V_{th} then V_m \\rightarrow V_{reset}\n\n\nCode\nimport numpy as np\n\n\nC_m = 2.e-9\nE_L = -70.e-3\nE_K = -80e-3\nR_m = 5.e6\nG_L = 1./R_m\nV_th = -50.e-3\nV_reset = -65.e-3\n\ntau_m = C_m/G_L\n\ndt = 0.1e-3\n\ntimes = np.arange(0, 200.e-3, dt)\nV = np.zeros_like(times)\n\nI_th = G_L*(V_th - E_L)\nI = np.ones_like(times) * I_th \n\nV[0] = E_L\n\ndef dvdt(V_m, I_app, G_ref=None):\n    value = (E_L - V_m)/R_m + I_app \n    if G_ref is not None:\n        value = value + G_ref* (E_K- V_m)\n    value = value/C_m\n    return value\n\n\ndef simulate(V, I, noises=None, tau_ref=None, tau_vth=None, V_th_array=None, G_ref=None, tau_Gref=None):\n    num_fire = 0\n    last_fire_time = -100\n\n    dvthdt_array = []\n    for i in range(1, len(times)):\n        if G_ref is None:\n            V_new = V[i-1] + dvdt(V[i-1], I[i-1]) * dt\n        else:\n            V_new = V[i-1] + dvdt(V[i-1], I[i-1], G_ref[i-1]) * dt\n                \n        if tau_vth is not None:\n            dvthdt = (-50e-3 - V_th_array[i-i]) / tau_vth\n            dvthdt_array.append(V_th_array[i-i])\n            V_th_array[i] = V_th_array[i-1] + dt*dvthdt\n        \n        if G_ref is not None:            \n            dG_refdt = -G_ref[i-1]/tau_Gref\n            G_ref[i] = G_ref[i-1] + dt * dG_refdt\n        if tau_vth is not None:\n            \n            if V_new > V_th_array[i-1]:  # Fire\n                V_new = V_reset\n                num_fire += 1\n                \n                V_th_array[i-1] = 200e-3\n                \n                if G_ref is not None: \n                    \n                    G_ref[i] =G_ref[i]+ 2e-6\n                                   \n        else:\n            if V_new > V_th: \n                V_new = V_reset\n                num_fire += 1\n                last_fire_time = times[i]\n        \n        if noises is not None:\n            V_new += noises[i]\n        \n        if tau_ref is not None:\n            if times[i] - last_fire_time < tau_ref:\n                V_new = V_reset\n        \n        V[i] = V_new\n    \n    fire_rate = num_fire/(times[-1] - times[0])\n    \n    if tau_vth is not None:\n        return fire_rate, dvthdt_array\n    return fire_rate\n\n\n1b What is the minimum required applied current for a spike?\nThe equation for the current threshold is I_{th} = G_L(V_{th} - E_L)\n\n\nCode\nI_th = G_L * (V_th - E_L)\nprint(f'I_th : {I_th}')\n\n\nI_th : 4e-09\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\n\nV_1 = np.copy(V)\nV_2 = np.copy(V)\nsimulate(V_1, np.ones_like(V_1) * I_th*.99)\nsimulate(V_2, np.ones_like(V_1) * I_th*1.01)\n\nplt.figure()\nplt.plot(times, V_1)\nplt.xlabel('Time (s) ')\nplt.ylabel('Voltage (V) ')\nplt.title('Applied current is : $0.99 * I_{th}$ ')\n\nplt.figure()\nplt.plot(times, V_2)\nplt.xlabel('Time (s) ')\nplt.ylabel('Voltage (V) ')\nplt.title('Applied current is : $1.01 * I_{th}$ ')\n\n\nText(0.5, 1.0, 'Applied current is : $1.01 * I_{th}$ ')\n\n\n\n\n\n\n\n\nBy plotting the voltage vs time plots the equation for the current threshold is validated; we can see that for slightly (1%) below the threshold current I_{th} no spikes are generated, but when increased to higher than the threshold current, many spikes can be seen.\n1c&d Change I_{app} and measure the average firing rate (f) varies in the range from 0 to 100Hz, and then verify the equation.\n\n\nCode\nfr_array = []\nfr_eq_array = []    \ndef fr_func(I):\n    value = tau_m * np.log(max(0.00001, I * R_m + E_L - V_reset)) - tau_m * np.log(max(0.000001, I*R_m + E_L-V_th))\n    value = 1./value\n    return value\n\n\nfor I in np.arange(4e-10, 1e-8, 1e-9):\n    V_3 = np.copy(V)\n    fr = simulate(V_3, np.ones_like(times) * I)\n    fr_array.append(fr)\n    fr_eq = fr_func(I)\n    fr_eq_array.append(fr_eq)\nfig = plt.figure()\n\nplt.plot(np.arange(4e-10, 1e-8, 1e-9),fr_array)\n\n\nplt.plot(np.arange(4e-10, 1e-8, 1e-9),fr_eq_array)\n\nplt.xlabel('Applied current $I_{app}$')\nplt.ylabel('Firing rate $f(hz)$') \n_=plt.title('$I_{app}$ vs firing rate $f$')\n\n\n\n\n\nAdd a noise term for each time step.\n\n\nCode\nV_4 = np.copy(V)\n\nnoises_fn = lambda sigma_I:  np.random.normal(size=times.shape) * sigma_I * np.sqrt(dt)\n\nplt.figure()\nfor sigma_I in range(0, 5,):\n    fr_array = []\n    for I in np.arange(4e-10, 1e-8, 1e-9):\n        V_4 = np.copy(V)\n        fr = simulate(V_4, np.ones_like(times) * I, noises_fn(sigma_I))\n        fr_array.append(fr)\n    \n        \n\n    plt.plot(np.arange(4e-10, 1e-8, 1e-9), fr_array)\n\n\n\n\n\nLooks like as sigma_I increases the f-r curve slope is decreased, also the curve is less smooth."
  },
  {
    "objectID": "base/CompNeuro/cns.html#tutorial-2.2",
    "href": "base/CompNeuro/cns.html#tutorial-2.2",
    "title": "Computation neural science",
    "section": "Tutorial 2.2",
    "text": "Tutorial 2.2\n\n\nCode\nC_m = 0.1e-9\nE_L = -70.e-3\nR_m = 100.e6\nG_L = 1./R_m\nV_th = -50e-3\nV_reset = -65.e-3\n\ntau_m = C_m/G_L\nI_th = G_L*(V_th - E_L)\n\nfr_array_1 = [] # Forced voltage clamp method\nmean_V_1 = []\n\nfr_array_2 = [] # Threshold increase\nmean_V_2 = []\n\nfr_array_3 = [] # Threshold increase\nmean_V_3 = []\nI_array = np.arange(100e-12, 600e-12, 50e-12)\n\nfor I in I_array:\n    V_1 = np.copy(V)\n    fr_1 = simulate(V_1, np.ones_like(times) * I, tau_ref=2.5e-3)\n    fr_array_1.append(fr_1)\n    mean_V_1.append(np.mean(V_1))\n    \n    V_2 = np.copy(V)\n    V_th_array = np.zeros_like(times)\n    V_th_array[0] = V_th\n    fr_2,dvthdt_array = simulate(V_2, np.ones_like(times) * I, tau_vth=1e-3, V_th_array=V_th_array)\n    fr_array_2.append(fr_2)\n    mean_V_2.append(np.mean(V_2))\n    \n    \n    V_3 = np.copy(V)\n    V_th_array = np.zeros_like(times)\n    G_ref = np.zeros_like(times)\n    V_th_array[0] = V_th\n    G_ref[0] = 0.\n    fr_3,_ = simulate(V_3, np.ones_like(times) * I, tau_vth=1e-3, V_th_array=V_th_array, G_ref=G_ref, tau_Gref=0.2e-3)\n    print(fr_3)\n    fr_array_3.append(fr_3)\n    mean_V_3.append(np.mean(V_3))\nfig = plt.figure().suptitle('current vs fr')\n\nplt.plot(I_array, fr_array_1, label='forced voltage clamp')\nplt.plot(I_array, fr_array_2, label='threshold increase')\nplt.plot(I_array, fr_array_3, label='refractory conductance')\nplt.xlabel('I')\nplt.ylabel('fr')\nplt.legend(loc='lower right')\nplt.figure().suptitle('current vs mean V')\nplt.plot(I_array, mean_V_1,  label='forced voltage clamp')\nplt.plot(I_array, mean_V_2, label='threshold increase')\nplt.plot(I_array, mean_V_3, label='refractory')\nplt.xlabel('I')\nplt.ylabel('Mean V')\nplt.legend(loc='lower right')\nplt.figure().suptitle('  fr vs mean V')\nplt.plot( fr_array_1,mean_V_1, label='forced voltage clamp')\nplt.plot( fr_array_2,mean_V_2,label='threshold increase')\nplt.plot( fr_array_3,mean_V_3,label='refractory')\nplt.xlabel('fr')\nplt.ylabel('Mean V')\nplt.legend(loc='lower right')\n\nplt.figure().suptitle('  V vst ')\nplt.plot( times,V_1, label='forced voltage clamp')\n#plt.plot( times,V_2,label='threshold increase')\nplt.xlabel('fr')\nplt.ylabel('Mean V')\nplt.legend(loc='lower right') \n\n\n0.0\n0.0\n0.0\n50.02501250625312\n70.03501750875436\n90.04502251125562\n105.05252626313155\n120.06003001500748\n140.07003501750873\n155.0775387693847\n\n\n<matplotlib.legend.Legend at 0x11ce453a0>"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/pyzmq-24.0.1.dist-info/AUTHORS.html",
    "href": "env2/lib/python3.8/site-packages/pyzmq-24.0.1.dist-info/AUTHORS.html",
    "title": "Welcome",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/etils/epath/docs/intro.html",
    "href": "env2/lib/python3.8/site-packages/etils/epath/docs/intro.html",
    "title": "Welcome",
    "section": "",
    "text": "[TOC]\nHave a look at the pathlib documentation if you’re not familiar with pathlib.\n\n\nPathlib API cleanup many very common file manipulation patterns.\n\n\n\n\nos.path\n\n\npathlib\n\n\n\n\npath = os.path.join(os.path.dirname(path), 'images')\n\n\n\npath = path.parent / 'images'\n\n\n\n\n\nwith tf.io.gfile.GFile(path, 'w') as f:\n  f.write(content)\n\n\n\npath.write_text(content)\n\n\n\n\n\nwith tf.io.gfile.GFile(path, 'rb') as f:\n  content = f.read()\n\n\n\ncontent = path.read_bytes()\n\n\n\n\n\nif not tf.io.gfile.exists(path):\n  tf.io.gfile.mkdirs(path)\n\n\n\npath.mkdir(parents=True, exist_ok=True)\n\n\n\n\n\nos.path.basename(path).split('.')[0]\n\n\n\npath.stem\n\n\n\n\n\nos.path.splitext(path)[1]\n\n\n\npath.suffix\n\n\n\n\n\n\n\nSome libraries are not compatible with pathlib. If the library cannot be fixed to be PEP 519 compliant, you can convert pathlib object to str with os.fspath, like:\npath = os.fspath(path)  # Convert `Path` -> `str`\n\n\n\nFunction inputs: Annotate with epath.PathLike to support both str and pathlib objects ( PEP 519 compliant):\ndef save(path: epath.PathLike):\n  path = epath.Path(path)  # Normalize `str`,... -> `Path`\n  ...\n\n\n# All the following are valid\nsave('/some/path')\nsave('gs://some-bucket/path')\nsave(pathlib.Path('/some/path'))\nsave(epath.Path('gs://some-bucket/path'))\nFunction outputs: Annotate with epath.Path.\n\n\n\n\nTo create a path:\npath = epath.Path('gs://path/to/my_directory')\nMost commonly used attributes:\n\n\n\nAttribute\nValue\n\n\n\n\npath\nPath('/path/to/file.txt')\n\n\npath.parent\nPath('/path/to/')\n\n\npath.name\n'file.txt'\n\n\npath.suffix\n'.txt'\n\n\npath.stem\n'file'\n\n\npath.parts\n('/', 'path', 'to', 'file.txt')\n\n\n\nMost commonly used methods:\n\npath / 'subdir' (instead of os.path.join(path, 'subdir'))\npath.exists()\npath.is_dir()\nfor p in path.iterdir()\nfor p in path.glob('*.jpg')\npath.mkdir()\npath.mkdir(parents=True, exist_ok=True)\n\nReading/writing files is also simplified. Instead of with open()::\n\npath.write_text(content)\npath.write_bytes(content)\npath.write_text()\npath.read_bytes()\nWhen used with other libraries:\nwith path.open('rb') as f:\n  csv.writer(f)\n\nTo convert:\n\nstr -> pathlib-like: epath.Path('/my/path')\npathlib-like -> str: os.fspath(my_path)\n\nSee pathlib doc for more info."
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/jupyter_client-7.4.2.dist-info/licenses/COPYING.html",
    "href": "env2/lib/python3.8/site-packages/jupyter_client-7.4.2.dist-info/licenses/COPYING.html",
    "title": "Welcome",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-2015, IPython Development Team\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbformat-5.7.0.dist-info/licenses/COPYING.html",
    "href": "env2/lib/python3.8/site-packages/nbformat-5.7.0.dist-info/licenses/COPYING.html",
    "title": "Welcome",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-2015, IPython Development Team\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/traitlets-5.4.0.dist-info/licenses/COPYING.html",
    "href": "env2/lib/python3.8/site-packages/traitlets-5.4.0.dist-info/licenses/COPYING.html",
    "title": "Welcome",
    "section": "",
    "text": "Traitlets is adapted from enthought.traits, Copyright (c) Enthought, Inc., under the terms of the Modified BSD License.\nThis project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-, IPython Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the IPython Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe IPython Development Team is the set of all contributors to the IPython project. This includes all of the IPython subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nIPython uses a shared copyright model. Each contributor maintains copyright over their contributions to IPython. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the IPython source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire IPython Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the IPython repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/jupyter_core-4.11.1.dist-info/license_files/COPYING.html",
    "href": "env2/lib/python3.8/site-packages/jupyter_core-4.11.1.dist-info/license_files/COPYING.html",
    "title": "Welcome",
    "section": "",
    "text": "Jupyter is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects. A full list with details is kept in the documentation directory, in the file about/credits.txt.\nThe core team that coordinates development on GitHub can be found here: https://github.com/ipython/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. It is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/UnicodePy3.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/UnicodePy3.html",
    "title": "Welcome",
    "section": "",
    "text": "print('☃')\n\n☃"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/JupyterWidgets.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/JupyterWidgets.html",
    "title": "Welcome",
    "section": "",
    "text": "# it should also handle custom msg'es\nlabel.send({'msg': 'Hello'})"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Other Comms.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Other Comms.html",
    "title": "Welcome",
    "section": "",
    "text": "comm = Comm('this-comm-tests-a-missing-handler', data={'id': 'foo'})\n\n\ncomm.send(data={'id': 'bar'})"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/SVG.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/SVG.html",
    "title": "Welcome",
    "section": "",
    "text": "SVG(data='''\n<svg height=\"100\" width=\"100\">\n    <circle cx=\"50\" cy=\"50\" r=\"40\" stroke=\"black\" stroke-width=\"2\" fill=\"red\" />\n</svg>''')"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Disable Stdin.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Disable Stdin.html",
    "title": "Welcome",
    "section": "",
    "text": "try:\n    input = raw_input\nexcept:\n    pass\n\nname = input(\"name: \")"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Autokill.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Autokill.html",
    "title": "Welcome",
    "section": "",
    "text": "import os\nimport signal\npid = os.getpid()\nos.kill(pid, signal.SIGTERM)"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/update-display-id.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/update-display-id.html",
    "title": "Welcome",
    "section": "",
    "text": "display('above')\ndisplay_with_id(1, 'here')\ndisplay('below')\n\n'above'\n\n\n8\n\n\n'below'\n\n\n\ndisplay_with_id(2, 'here')\ndisplay_with_id(3, 'there')\ndisplay_with_id(4, 'here')\n\n8\n\n\n6\n\n\n8\n\n\n\ndisplay_with_id(5, 'there')\ndisplay_with_id(6, 'there', update=True)\n\n6\n\n\n\ndisplay_with_id(7, 'here')\ndisplay_with_id(8, 'here', update=True)\ndisplay_with_id(9, 'result', execute_result=True)\n\n8\n\n\n10\n\n\n\ndisplay_with_id(10, 'result', update=True)"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Inline Image.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Inline Image.html",
    "title": "Welcome",
    "section": "",
    "text": "Image('python.png')"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Interrupt.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Interrupt.html",
    "title": "Welcome",
    "section": "",
    "text": "print(\"done\")\n\ndone"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Factorials.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Factorials.html",
    "title": "Welcome",
    "section": "",
    "text": "for m in range(10):\n    i, j = j, i + j\n    print(j)\n\n2\n3\n5\n8\n13\n21\n34\n55\n89\n144"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Skip Exceptions with Cell Tags.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Skip Exceptions with Cell Tags.html",
    "title": "Welcome",
    "section": "",
    "text": "print('ok')\n\nok"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Check History in Memory.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Check History in Memory.html",
    "title": "Welcome",
    "section": "",
    "text": "ip = get_ipython()\nassert ip.history_manager.hist_file == ':memory:'"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Output.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Output.html",
    "title": "Welcome",
    "section": "",
    "text": "print(\"hi\")\nwith output1:\n    print(\"in output\")\n\nhi\n\n\n\nwith output1:\n    raise ValueError(\"trigger msg_type=error\")\n\n\nimport ipywidgets as widgets\noutput2 = widgets.Output()\noutput2\n\n\n\n\n\nprint(\"hi2\")\nwith output2:\n    print(\"in output2\")\n    clear_output(wait=True)\n\nhi2\n\n\n\nimport ipywidgets as widgets\noutput3 = widgets.Output()\noutput3\n\n\n\n\n\nprint(\"hi3\")\nwith output3:\n    print(\"hello\")\n    clear_output(wait=True)\n    print(\"world\")\n\nhi3\n\n\n\nimport ipywidgets as widgets\noutput4 = widgets.Output()\noutput4\n\n\n\n\n\nprint(\"hi4\")\nwith output4:\n    print(\"hello world\")\n    clear_output()\n\nhi4\n\n\n\nimport ipywidgets as widgets\noutput5 = widgets.Output()\noutput5\n\n\n\n\n\nprint(\"hi5\")\nwith output5:\n    display(\"hello world\") # this is not a stream but plain text\nclear_output()\n\n\nimport ipywidgets as widgets\noutput_outer = widgets.Output()\noutput_inner = widgets.Output()\noutput_inner\n\n\n\n\n\noutput_outer\n\n\n\n\n\nwith output_inner:\n    print('in inner')\n    with output_outer:\n        print('in outer')\n    print('also in inner')"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Clear Output.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Clear Output.html",
    "title": "Welcome",
    "section": "",
    "text": "for i in range(10):\n    clear_output()\n    print(i)\n\n9\n\n\n\nprint(\"Hello world\")\nclear_output()\n\n\nprint(\"Hello world\", end='')\nclear_output(wait=True)  # no output after this\n\nHello world\n\n\n\nprint(\"Hello\", end='')\nclear_output(wait=True)  # here we have new output after wait=True\nprint(\"world\", end='')\n\nworld\n\n\n\nhandle0 = display(\"Hello world\", display_id=\"id0\")\n\n'Hello world'\n\n\n\nhandle1 = display(\"Hello\", display_id=\"id1\")\n\n'world'\n\n\n\nhandle1.update('world')\n\n\nhandle2 = display(\"Hello world\", display_id=\"id2\")\nclear_output()  # clears all output, also with display_ids\n\n\nhandle3 = display(\"Hello world\", display_id=\"id3\")\nclear_output(wait=True)\n\n'Hello world'\n\n\n\nhandle4 = display(\"Hello\", display_id=\"id4\")\nclear_output(wait=True)\nprint('world', end='')\n\nworld\n\n\n\nhandle4.update('Hello world')  # it is cleared, so it should not show up in the above cell"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Parallel Execute A.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Parallel Execute A.html",
    "title": "Welcome",
    "section": "",
    "text": "This notebook uses a file system based “lock” to assert that two instances of the notebook kernel will run in parallel. Each instance writes to a file in a temporary directory, and then tries to read the other file from the temporary directory, so that running them in sequence will fail, but running them in parallel will succeed.\nTwo notebooks are launched, each which sets the this_notebook variable. One notebook is set to this_notebook = 'A' and the other this_notebook = 'B'.\n\nimport os\nimport os.path\nimport tempfile\nimport time\n\n\n# the variable this_notebook is injectected in a cell above by the test framework.\nthis_notebook = 'A'\nother_notebook = 'B'\ndirectory = os.environ['NBEXECUTE_TEST_PARALLEL_TMPDIR']\nwith open(os.path.join(directory, 'test_file_{}.txt'.format(this_notebook)), 'w') as f:\n    f.write('Hello from {}'.format(this_notebook))\n\n\nstart = time.time()\ntimeout = 5\nend = start + timeout\ntarget_file = os.path.join(directory, 'test_file_{}.txt'.format(other_notebook))\nwhile time.time() < end:\n    time.sleep(0.1)\n    if os.path.exists(target_file):\n        with open(target_file, 'r') as f:\n            text = f.read()\n        if text == 'Hello from {}'.format(other_notebook):\n            break\nelse:\n    assert False, \"Timed out – didn't get a message from {}\".format(other_notebook)"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Empty Cell.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Empty Cell.html",
    "title": "Welcome",
    "section": "",
    "text": "\"Code 1\"\n\n'Code 1'\n\n\n\n\"Code 2\"\n\n'Code 2'"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Skip Execution with Cell Tag.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Skip Execution with Cell Tag.html",
    "title": "Welcome",
    "section": "",
    "text": "print('ok')\n\nok"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Parallel Execute B.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Parallel Execute B.html",
    "title": "Welcome",
    "section": "",
    "text": "This notebook uses a file system based “lock” to assert that two instances of the notebook kernel will run in parallel. Each instance writes to a file in a temporary directory, and then tries to read the other file from the temporary directory, so that running them in sequence will fail, but running them in parallel will succeed.\nTwo notebooks are launched, each which sets the this_notebook variable. One notebook is set to this_notebook = 'A' and the other this_notebook = 'B'.\n\nimport os\nimport os.path\nimport tempfile\nimport time\n\n\n# the variable this_notebook is injectected in a cell above by the test framework.\nthis_notebook = 'B'\nother_notebook = 'A'\ndirectory = os.environ['NBEXECUTE_TEST_PARALLEL_TMPDIR']\nwith open(os.path.join(directory, 'test_file_{}.txt'.format(this_notebook)), 'w') as f:\n    f.write('Hello from {}'.format(this_notebook))\n\n\nstart = time.time()\ntimeout = 5\nend = start + timeout\ntarget_file = os.path.join(directory, 'test_file_{}.txt'.format(other_notebook))\nwhile time.time() < end:\n    time.sleep(0.1)\n    if os.path.exists(target_file):\n        with open(target_file, 'r') as f:\n            text = f.read()\n        if text == 'Hello from {}'.format(other_notebook):\n            break\nelse:\n    assert False, \"Timed out – didn't get a message from {}\".format(other_notebook)"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Unicode.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Unicode.html",
    "title": "Welcome",
    "section": "",
    "text": "print('☃')\n\n☃"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/HelloWorld.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/HelloWorld.html",
    "title": "Welcome",
    "section": "",
    "text": "print(\"Hello World\")\n\nHello World"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Sleep1s.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Sleep1s.html",
    "title": "Welcome",
    "section": "",
    "text": "t0 = datetime.datetime.utcnow()\ntime.sleep(1)\nt1 = datetime.datetime.utcnow()\n\n\ntime_format = '%Y-%m-%dT%H:%M:%S.%fZ'\nprint(t0.strftime(time_format), end='')\n\n\nprint(t1.strftime(time_format), end='')"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Error.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Error.html",
    "title": "Welcome",
    "section": "",
    "text": "0/0\n\nZeroDivisionError: division by zero"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/nbclient/tests/files/Skip Exceptions.html",
    "href": "env2/lib/python3.8/site-packages/nbclient/tests/files/Skip Exceptions.html",
    "title": "Welcome",
    "section": "",
    "text": "print('ok')\n\nok"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/ipykernel-6.16.0.dist-info/licenses/COPYING.html",
    "href": "env2/lib/python3.8/site-packages/ipykernel-6.16.0.dist-info/licenses/COPYING.html",
    "title": "Welcome",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2015, IPython Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the IPython Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe IPython Development Team is the set of all contributors to the IPython project. This includes all of the IPython subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/ipython/.\n\n\n\nIPython uses a shared copyright model. Each contributor maintains copyright over their contributions to IPython. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the IPython source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire IPython Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the IPython repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "env2/lib/python3.8/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "Welcome",
    "section": "",
    "text": "from imp import reload"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "href": "env2/lib/python3.8/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "title": "Welcome",
    "section": "UAT for NbAgg backend.",
    "text": "UAT for NbAgg backend.\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\n\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)\n\n\nUAT 1 - Simple figure creation using pyplot\nShould produce a figure window which is interactive with the pan and zoom buttons. (Do not press the close button, but any others may be used).\n\nimport matplotlib.backends.backend_webagg_core\nreload(matplotlib.backends.backend_webagg_core)\n\nimport matplotlib.pyplot as plt\nplt.interactive(False)\n\nfig1 = plt.figure()\nplt.plot(range(10))\n\nplt.show()\n\n\n\nUAT 2 - Creation of another figure, without the need to do plt.figure.\nAs above, a new figure should be created.\n\nplt.plot([3, 2, 1])\nplt.show()\n\n\n\nUAT 3 - Connection info\nThe printout should show that there are two figures which have active CommSockets, and no figures pending show.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 4 - Closing figures\nClosing a specific figure instance should turn the figure into a plain image - the UI should have been removed. In this case, scroll back to the first figure and assert this is the case.\n\nplt.close(fig1)\nplt.close('all')\n\n\n\nUAT 5 - No show without plt.show in non-interactive mode\nSimply doing a plt.plot should not show a new figure, nor indeed update an existing one (easily verified in UAT 6). The output should simply be a list of Line2D instances.\n\nplt.plot(range(10))\n\n\n\nUAT 6 - Connection information\nWe just created a new figure, but didn’t show it. Connection info should no longer have “Figure 1” (as we closed it in UAT 4) and should have figure 2 and 3, with Figure 3 without any connections. There should be 1 figure pending.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 7 - Show of previously created figure\nWe should be able to show a figure we’ve previously created. The following should produce two figure windows.\n\nplt.show()\nplt.figure()\nplt.plot(range(5))\nplt.show()\n\n\n\nUAT 8 - Interactive mode\nIn interactive mode, creating a line should result in a figure being shown.\n\nplt.interactive(True)\nplt.figure()\nplt.plot([3, 2, 1])\n\nSubsequent lines should be added to the existing figure, rather than creating a new one.\n\nplt.plot(range(3))\n\nCalling connection_info in interactive mode should not show any pending figures.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\nDisable interactive mode again.\n\nplt.interactive(False)\n\n\n\nUAT 9 - Multiple shows\nUnlike most of the other matplotlib backends, we may want to see a figure multiple times (with or without synchronisation between the views, though the former is not yet implemented). Assert that plt.gcf().canvas.manager.reshow() results in another figure window which is synchronised upon pan & zoom.\n\nplt.gcf().canvas.manager.reshow()\n\n\n\nUAT 10 - Saving notebook\nSaving the notebook (with CTRL+S or File->Save) should result in the saved notebook having static versions of the figures embedded within. The image should be the last update from user interaction and interactive plotting. (check by converting with ipython nbconvert <notebook>)\n\n\nUAT 11 - Creation of a new figure on second show\nCreate a figure, show it, then create a new axes and show it. The result should be a new figure.\nBUG: Sometimes this doesn’t work - not sure why (@pelson).\n\nfig = plt.figure()\nplt.axes()\nplt.show()\n\nplt.plot([1, 2, 3])\nplt.show()\n\n\n\nUAT 12 - OO interface\nShould produce a new figure and plot it.\n\nfrom matplotlib.backends.backend_nbagg import new_figure_manager,show\n\nmanager = new_figure_manager(1000)\nfig = manager.canvas.figure\nax = fig.add_subplot(1,1,1)\nax.plot([1,2,3])\nfig.show()"
  },
  {
    "objectID": "env2/lib/python3.8/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "env2/lib/python3.8/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "Welcome",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  },
  {
    "objectID": "blog/nerf/nerf.html",
    "href": "blog/nerf/nerf.html",
    "title": "Home",
    "section": "",
    "text": "Given a set of images for a scene, we can construct a representation of the scene using a neural network through integration - how awesomely cool is that! The NeRF model [@Mildenhall2020] is a neural network which integrates many different rays coming towards the camera that forms an image. It uses a multi-layered perception (or MLP), that can be trained to represent a scene from a set of images, and after training we can synthesis an image taken from a new angle.\nWhen I first read the NeRF paper, I was quite excited about it. I was thinking that this is a great way to learn about 3D reconstruction, and also learn about how neural networks are used for scene reconstruction. I was also thinking that this is a great way to learn about JAX, since I have only been using Tensorflow and PyTorch.\nBefore coding up NeRF, understanding the paper is important. The paper is quite short, and it is easy to understand. I would recommend reading the paper first, and then come back to this blog. I’ve also listed all of the reference materials I’ve used for this project."
  },
  {
    "objectID": "blog/blog.html",
    "href": "blog/blog.html",
    "title": "Blogs yo",
    "section": "",
    "text": "Links: * Github: https://github.com/higgsboost/nerf-jax\nBlog: nerf(WIP)\nexample"
  },
  {
    "objectID": "blog/nerf/nerf.html#hierarchical-volume-sampling",
    "href": "blog/nerf/nerf.html#hierarchical-volume-sampling",
    "title": "Home",
    "section": "Hierarchical volume sampling",
    "text": "Hierarchical volume sampling\nFree space and solid objects don’t contribute to the final color, so we can sample the volume more densely around points along the ray that have a larger weight - this is called hierarchical volume sampling.\nFirst sample a coarse set of points, then they sample a fine set of points around the coarse set.\nThis method is used to sample points closer to the surface of the objects. They first sample \\(N_c\\) locations using stratified sampling, then they sample a second set \\(N_f\\) using inverse transform sampling of the \\(\\text{PDF}\\) created using \\(w_i = T_i(1-\\exp(-\\sigma_i \\delta_i))\\), or\n\\[\nf_X(x) = \\frac{T_x(1-\\exp(-\\sigma_x \\delta_x))}{k} \\quad 1 < x < N_c\n\\]\nwhere \\(k=\\sum_j^{N_c} w_j\\) is the normalizing factor, this is the ensure that the area under the \\(\\text{PDF}\\) is 1. Let’s plot the PDF for a ray (with 128 points) at the center of the image, and also verify that the area is 1 under the curve.\n\n\nCode\nimport numpy as np\nweights = np.squeeze(np.load('weights.npy'))\n\nk = np.sum(weights) \n# normalize\nweights = weights/k\ndx = 1. \nx=np.arange(0, 128)\n\nimport plotly.express as px\nfig = px.line(x=x, y=weights, \\\n    labels={\n        'x': \"counter along x\",\n        'y': \"probability\"\n    }, title='PDF of weights')\nfig.show()\n\n# area\narea = np.sum(weights * dx)\nprint(f'Area under the curve is :{area}')\n\n\n\n                                                \n\n\nArea under the curve is :1.0\n\n\n\nInverse transform sampling\nThe idea behind inverse transform sampling is to use the inverse of the \\(\\text{CDF}\\) to generate random numbers for a probability distribution. The \\(\\text{CDF}\\) for a random variable \\(X\\) is \\(F_X(x) = P(X\\leq x)\\). Then, generate random numbers from a uniform distribution \\(Z \\sim \\text{uni}(0, 1)\\), using this with the inverse \\(\\text{CDF}\\) (or \\(F^{-1}_X(Z)\\)) to get samples from the original distribution.\nLet’s plot the CDF and the inverse cdf.\n\n\nCode\ncdf = np.cumsum(weights)\nfig = px.line(x=x, y=cdf, title=\"CDF \", labels={\n    'x': 'counter along x',\n    'y': 'probability'\n})\nfig.show()\n\nfig = px.line(x=cdf, y=x, title=\"Inverse CDF \", labels={\n    'y': 'counter along x',\n    'x': 'probability'\n})\nfig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\nWe can see that if we sample the inverse cdf - with a uniform distribution - the value of the y-axis (or the counter along the x-axis) would fall around 55, which corresponds to the section with the highest probability density of the pdf plot.\nLet’s plot a histogram of 1000 sampled counter using inverse transform sampling method.\n\n\nCode\nimport jax.numpy as jnp \nimport jax\nZ = jax.random.uniform(key=jax.random.PRNGKey(0), shape=[1000])\ncdf = jnp.array(cdf)\n\ndef inverse_cdf(prob, cdf):\n    x = jnp.linspace(2, 6, 128)\n    abs_diff = jnp.abs(prob[..., jnp.newaxis] - cdf[jnp.newaxis, ...])\n    argmin = jnp.argmin(abs_diff, -1)\n    return x[argmin]\n\nX = inverse_cdf(Z, cdf)\n\n \nfig = px.histogram(x=X, labels={'x':'distance along the camera ray '})\nfig.show()\n\n\n\n                                                \n\n\n\nt = np.load('../../t.npy')\nprint(t.shape)\n\nfig = px.histogram(x=t[50,50])\nfig.show()\n\n(100, 100, 128)"
  },
  {
    "objectID": "blog/blog.html#a",
    "href": "blog/blog.html#a",
    "title": "Blogs yo",
    "section": "a",
    "text": "a\na"
  },
  {
    "objectID": "base/probability/probability.html#simulations",
    "href": "base/probability/probability.html#simulations",
    "title": "Basic Probability",
    "section": "Simulations",
    "text": "Simulations\n\nMonte Hall simulation\n\n\nCode\nimport numpy as np\nimport random\nfrom tqdm import tqdm\n\ndef mt(switch):\n  win_array = []\n  for _ in range(num_sim):\n    # 1 - car\n    prizes = np.arange(1, 4)\n    random.shuffle(prizes)\n\n    pick_id = np.random.randint(0, 3)\n    car_id,  = np.where(prizes == 1) \n\n    allowed = [0,1,2]\n    allowed.remove(pick_id)\n    host_allowed = allowed.copy()\n\n    if prizes[pick_id] != 1:\n      host_allowed.remove(car_id[0])\n\n    allowed.remove(host_allowed[0])\n\n    if switch:\n      if prizes[allowed[0]] == 1: \n        win_array.append(1) \n      else:\n        win_array.append(0)\n    else:\n      if prizes[pick_id] == 1: \n        win_array.append(1) \n      else:\n        win_array.append(0)\n  return np.sum(win_array)/float(num_sim)\n\nprint(f'After {num_sim} games')\nprint(f'Probability of winning the car with switching is {mt(1)} ')\nprint(f'Probability of winning the car without switching is {mt(0)} ')\n\n\nAfter 1000 games\nProbability of winning the car with switching is 0.689 \nProbability of winning the car without switching is 0.349"
  },
  {
    "objectID": "base/probability/probability.html#cool-simulations",
    "href": "base/probability/probability.html#cool-simulations",
    "title": "Basic Probability",
    "section": "Cool simulations",
    "text": "Cool simulations\n\nMonte Hall simulation\n\n\nCode\nimport numpy as np\nimport random\nfrom tqdm import tqdm\n\ndef mt(switch):\n  win_array = []\n  for _ in range(num_sim):\n    # 1 - car\n    prizes = np.arange(1, 4)\n    random.shuffle(prizes)\n\n    pick_id = np.random.randint(0, 3)\n    car_id,  = np.where(prizes == 1) \n\n    allowed = [0,1,2]\n    allowed.remove(pick_id)\n    host_allowed = allowed.copy()\n\n    if prizes[pick_id] != 1:\n      host_allowed.remove(car_id[0])\n\n    allowed.remove(host_allowed[0])\n\n    if switch:\n      if prizes[allowed[0]] == 1: \n        win_array.append(1) \n      else:\n        win_array.append(0)\n    else:\n      if prizes[pick_id] == 1: \n        win_array.append(1) \n      else:\n        win_array.append(0)\n  return np.sum(win_array)/float(num_sim)\n\nprint(f'After {num_sim} games')\nprint(f'Probability of winning the car with switching is {mt(1)} ')\nprint(f'Probability of winning the car without switching is {mt(0)} ')\n\n\nAfter 1000 games\nProbability of winning the car with switching is 0.655 \nProbability of winning the car without switching is 0.31"
  },
  {
    "objectID": "base/CompNeuro/htm.html",
    "href": "base/CompNeuro/htm.html",
    "title": "Computation neural science",
    "section": "",
    "text": "Introduction\n\nBit Arrays\nA bit array is a collection of bits, each of which can be either 0 or 1.\n\n\n\n\n\n\nHamming weight\n\n\n\n\n\nThe number of 1s in a bit array is called the Hamming weight.\n\n\n\nFor a bit array with 256 places, the capacity is 2^{256}, which is a very large number. Sparsity is the fraction of 1s in the array. HTM deals with the sparsity of around 2%.\n\n\nSparse Distributed Representation (SDR)\nThe SDR capacity is defined as #bits!/(#number on bits)!(#number off bits)!\n\nimport math\n\ndef sdr_capacity(num_bits, on_bits):\n  print(f'sparsity : {on_bits*100./num_bits} %')\n  return math.factorial(num_bits) / (math.factorial(on_bits) * math.factorial(num_bits - on_bits))\n\n\nn=256\non_bits = 5\nprint(f'Capcity for SDR with n={16} #onbits={on_bits}: {sdr_capacity(n, on_bits)}')\n\nn=256\non_bits = 10\nprint(f'Capcity for SDR with n={16} #onbits={on_bits}: {sdr_capacity(n, on_bits)}')\n\nsparsity : 1.953125 %\n\n\n\nCapcity for SDR with n=16 #onbits=5: 8809549056.0\nsparsity : 3.90625 %\nCapcity for SDR with n=16 #onbits=10: 2.788262146425184e+17\n\n\nThe capcity of a SDR is very large, and grows very fast with the number of on bits.\n\n\nOverlap\nIf we have an SDR with 2048 bits and 41 on bits, and we apply noise to it, we can still find the overlap between the original SDR and the noisy SDR.\n\n\nCode\nimport numpy as np\ndef random_sdr(num_bits, on_bits):\n  print(f'Creating random sdr with sparsity: {on_bits/num_bits}')\n  sdr = [0]*num_bits\n  for i in range(on_bits):\n    sdr[np.random.randint(0,num_bits)] = 1\n  return sdr\n\ndef apply_noise(sdr, noise):\n  # each on bit has a change to be another bit\n  sdr_copy = sdr.copy()\n  for i in range(len(sdr)):\n    if sdr[i] == 1 and np.random.random() < noise:\n      sdr_copy[i] = 0\n      sdr_copy[np.random.randint(0,len(sdr))] = 1\n  return sdr_copy\n\ndef find_overlap(sdr1, sdr2):\n  overlap = 0\n  for i in range(len(sdr1)):\n    if sdr1[i] == 1 and sdr2[i] == 1:\n      overlap += 1\n  return overlap\nsdr = random_sdr(2048, 41)\nsdr_noise = apply_noise(sdr, 0.30)\n\nprint(f'Hamming weight of sdr: {sum(sdr)}')\nprint(f'Hamming weight of sdr_noise: {sum(sdr_noise)}')\n\nprint(f'Overlap of sdr and sdr_noise: {find_overlap(sdr, sdr_noise)}')\n\n\nCreating random sdr with sparsity: 0.02001953125\nHamming weight of sdr: 40\nHamming weight of sdr_noise: 40\nOverlap of sdr and sdr_noise: 32\n\n\nTheta \\theta is the threshold for the overlap. If the overlap is greater than \\theta, then the SDRs are considered to be similar.\nThe overlap is 30, and the chance of a false positive is extremely low. Thus SDR can handle noise very well.\n\nSDR compression\nThe SDR can be compressed by simply returning the indices of the on bits.\n\ndef sdr_to_indices(sdr):\n  indices = np.where(np.array(sdr) == 1)[0]\n  return indices\n\ndef indices_to_sdr(indices, num_bits):\n  sdr = np.zeros(num_bits)\n  sdr[indices] = 1\n  return sdr\n\nsdr = random_sdr(16, 3)\nindices = sdr_to_indices(sdr)\nprint(f'SDR: {sdr}')\nprint(f'Indices: {indices}')\n\nCreating random sdr with sparsity: 0.1875\nSDR: [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\nIndices: [ 2  9 15]\n\n\n\n\n\nOverlap set\nThe overlap set \\Omega(n, w, b) is the set of all SDRs between SDR with n bits, w_x on bits, and w on bits with b required overlap bits. The length of the overlap set is C(w_x, b)C(n-w_x, w-b).\n\ndef combination(n, k):\n  return math.factorial(n) / (math.factorial(k) * math.factorial(n - k))\n\ndef len_overlap_set(n, wx, w, b):\n  len_set = combination(wx, b) * combination(n-wx, w-b) \n  chance_of_false_positive = len_set / combination(n, w)\n  print(f'Chance of false positive: {chance_of_false_positive}')\n  return len_set \n\nn=2048\nwx=40\nw=40\nb=30\nprint(f'n={n}, wx={wx}, w={w}, b={b}')\nprint(f'Overlap set length: {len_overlap_set(n, wx, w, b)} ')\n\nn=2048, wx=40, w=40, b=30\nChance of false positive: 1.0262987550838283e-49\nOverlap set length: 2.434153333836206e+35 \n\n\n\n\nSDR subsampling\nSince SDRs are so tolerant to noise, it is possible to take only a subset of the SDRs and still have a high chance of finding the correct SDR."
  },
  {
    "objectID": "base/base.html",
    "href": "base/base.html",
    "title": "Flashcard Links",
    "section": "",
    "text": "probability\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/nerf/nerf.html#the-network",
    "href": "blog/nerf/nerf.html#the-network",
    "title": "Home",
    "section": "The Network",
    "text": "The Network\nThe NeRF model represents a scene as a neural network, where at each 3D poisition \\(\\vec{x} \\in \\mathbb{R}^3\\) and viewing direction \\(\\vec{d} \\in \\mathbb{R}^3\\), and the output of the model is the color (RGB) \\(\\vec{c}\\) and the density \\(\\sigma\\) for that point in space. Thus we have:\n\\[\nF_\\Theta : ( \\vec{x}, \\vec{d}) \\rightarrow (\\vec{c}, \\sigma)\n\\]\nThe network \\(F_\\Theta\\) is an Multi-Layer Perceptron (MLP); the network is super simple illustrated in Figure 1, it is just a bunch of linear layers with ReLU activations. But, the authors’ designed the network to ensured that the volume density \\(\\sigma\\) is view independent (\\(\\partial{\\sigma} / \\partial{\\vec{d}} = 0\\)) by setting the directional input \\(\\vec{d}\\) after the \\(\\sigma\\) output.\n\n\n\n\n\nFigure 1: The NeRF model @Mildenhall2020. The blue blocks represents MLP layers. Black arrows indicates ReLU activation layer, orange arrow indicates no activation and dashed black line indicates sigmoid activiation.\n\n\n\nCamera ray and position encoding\n\nCamera ray\nBefore we can train the network, we need to generate the rays that will be used to train the network. The rays are generated from the camera, and the camera is defined by the extrinsic parameters - rotation and translation matrices - \\([R | T]\\), the focal length, and the near/far distances. The origin \\(\\vec{o}\\) would be the camera translation vector for that image.\nThe vector \\(\\vec{d}\\), can be thought of as \\(\\vec{d}= R\\vec{d}_o\\), where \\(\\vec{d}_o\\) is the direction vector \\(\\vec{d}_o = [x, y, -f]\\) using the pin-hole camera model [cite], the magnitude doesn’t maktter so \\(\\vec{d}_o = [x/f, y/f, -1]\\)\n\n\nPositional encoding\nThe positional encoding is a simple way to encode the 3D position \\(\\vec{x}\\) into a vector. The authors used a sine and cosine function to encode the position to enable the MLP to capture higher frequencey functions. The encoding is given by:\n\\[\n\\gamma(x) = (sin(2^0\\pi x), cos(2^0 x), \\dots, sin(2^{L-1}\\pi x), cos(2^{L-1} x))\n\\]\nwhere \\(x\\) can be either the position or the direction, and \\(L\\) is the number of frequencies. The authors used \\(L_{position}=10\\) and \\(L_{direction}=4\\).\n\n\nModel in JAX\nUsing Flax, we can easily define the model in JAX. The code is shown below:\n\n# code-fold: true\nimport jax\nimport flax.linen as nn\nimport jax.numpy as jnp\n\n\nclass Model(nn.Module):\n\n  @nn.compact\n  def __call__(self, position, direction):\n    x =  position\n\n    for i in range(7):\n        x = nn.Dense(256, name=f'fc{i + 1}')(x)\n        x = nn.relu(x)\n\n        # Concat x with original input \n        if i == 4:\n            x = jnp.concatenate([x, position], -1)\n\n    x = nn.Dense(256, name=f'fc{8}_linear')(x)\n\n    vol_density = nn.Dense(1, name=f'fc{8}_sigmoid')(x)\n\n    # Create an output for the volume density that is view independent\n    # and > 0 by using a relu activation function \n    vol_density = jax.nn.relu(vol_density)\n\n    # Concat direction information after the volume density\n    x = jnp.concatenate([x, direction], -1)\n    x = nn.Dense(128, name='fc_128')(x)\n    x = nn.relu(x)\n    x = nn.Dense(3, name='fc_f')(x)\n\n    # rgb color is between 0 and 1\n    rgb = nn.sigmoid(x)\n    return rgb, vol_density\n\n\nL_position = 10 \nL_direction = 4 \nrandom_position = jnp.ones((1, L_position * 6 + 3))\nrandom_direction = jnp.ones((1, L_direction * 6 + 3))\n\n\n\n\n\n\n\nTip\n\n\n\nUse the code below to print the model architecture\nprint(Model().tabulate(jax.random.PRNGKey(0), random_position, random_direction))\n\n\n\n\n\nHow does the network work?\nImagine a line or ray pointed towards the camera, with equation \\(\\vec{r}(t) = \\vec{o} +t \\vec{d}\\); where \\(\\vec{o}\\) is the origin point on the ray and \\(t\\) is a parameter controls how far along the ray we are at. The authors split the ray into \\(N\\) segments, where each segment will have length equaled to \\(\\delta_i = t_{i+1}-t_i\\). At each segment along the ray, we can find the color and density of segment \\(i\\) approximated by the neural network \\(F_\\Theta(\\vec{r}(t_i), \\vec{d_i}) \\rightarrow (\\vec{c}_i, \\sigma_i)\\). We can get the expected color that would appear on our image by using a set of approximation equations, outlined below:\n\\[\n\\hat{C}(\\vec{r}) = \\sum_{i=1}^{N} T_i a_i \\vec{c}_i\n\\]\nwhere,\n\\[\na_i = (1- \\text{exp}(-\\sigma_i \\delta_i))\n\\]\nand, \\[\nT_i=\\text{exp}\\left( -\\sum_{j=1}^{i-1} \\sigma_j \\delta_j \\right)\n\\]\n\\(T_i\\) for a segment, is the accumulated transmittance upto that point, which can be thought of as the the probability that the ray has not hit anything up to that point, so every point before a solid object along the ray, \\(T_i\\) should be \\(1\\). If the ray encounters some solid object, then \\(T_i\\) would start to decrease because the volume density \\(\\sigma\\) starts to increase. We can see that the alpha values \\(a_i\\) for low volume density becomes \\(0\\) which ignores that colour in the integral. What an interesting relationship!\nThe above equations can be written with jnp, a JAX version of numpy as:\n\n...\n# get the accumulated transmittance\nT_i = jnp.cumsum(jnp.squeeze(sigma) * t_delta + 1e-10, -1)\nT_i = jnp.insert(T_i, 0, jnp.zeros_like(T_i[...,0]),-1)\nT_i = jnp.exp(-T_i)[..., :-1]\n\n# get the alpha values\nalpha = (1.-jnp.exp(-sigma*t_delta[..., jnp.newaxis]))\n\nweights = T_i[..., jnp.newaxis] * alpha\nc_array = weights * rgb\nc_sum =jnp.sum(c_array, -2)\nreturn c_sum"
  },
  {
    "objectID": "blog/nerf/nerf.html#training",
    "href": "blog/nerf/nerf.html#training",
    "title": "Home",
    "section": "Training",
    "text": "Training"
  }
]