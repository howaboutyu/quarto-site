
---
title: Chapter 3 - Generating receptive fields with spike-triggered averages 
format: html
reference-location: margin
jupyter: python3
bibliography: ../../references.bib
html-math-method: katex
editor:
  render-on-save: true
---




```{python}
# | code-fold: true
import dataclasses
import numpy as np
from typing import List, Tuple, Union
import plotly.graph_objects as go
```




```{python}
from synapseflow.neuron_models.lif_model import LIFModel, AELIFModel
from synapseflow.neuron_models.neuron_parameters import NeuronParameters

from synapseflow.neuron_models.utils import expand_bins, STA, find_fano_factor

params = NeuronParameters(
    C_m=100e-12,
    E_L=-60.e-3,
    R_m=100.e6,
    E_K=-80.e-3,
    V_th=-50e-3,
    V_reset=-80.e-3,
    V_peak=50.e-3,
    tau_SRA=50e-3,
    a=10e-9,
    b=0.5e-9,
    Delta_th=2e-3,
    V_max=100e-3,    
)


params.G_L = 8e-9
```


## Time-varying stimulus

We will sample 40,000 currents from a uniform distribution $I \sim U(-0.5, 0.5)$ nA. We will then apply this current to the neuron for 5ms, this is to see how changes in the input current affect the neuron's firing rate.


```{python}

num_blocks = 4000
random_currents = np.random.uniform(-0.5, 0.5, size=num_blocks)
dt = 0.02e-3
times_5ms = np.arange(0, 5e-3, dt)
currents = np.repeat(random_currents, 250)

times = np.arange(0, num_blocks*5e-3, dt)
print(f'Times shape : {times.shape}')
print(f'Currents shape : {currents.shape}')

aelif_varying_current = AELIFModel(
    times=times,
    neuron_parameters=params,
    I=currents,
    noise_sigma=0,
)
aelif_varying_current.simulate()
```


```{python}
def expand_bins(spikes, new_dt, old_dt):
    sf = int(new_dt/old_dt)
    spikes = np.split(spikes, sf, axis=0)
    spikes = np.array(spikes)
    spikes = np.mean(spikes, axis=0)
    return spikes

spikes_original = aelif_varying_current.spike_array
print(f'Spikes original shape: {spikes_original.shape}')
spikes_downsampled = expand_bins(spikes_original, 1e-3, 0.02e-3)
spikes_downsampled = np.round(spikes_downsampled)
print(f'Downsampled spikes shape: {spikes_downsampled.shape}')

current_downsampled = expand_bins(currents, 1e-3, 0.02e-3)
```

```{python}
def STA(currents, spikes, dt, t_minus=72e-3, t_plus=25e-3):
    nminus = int(t_minus/dt)
    nplus = int(t_plus/dt)
    n = nminus + nplus + 1
    print(f'N: {n}')
    sta = np.zeros(n)

    for i in range(nminus, len(spikes)-nplus):
        if spikes[i] == 1:
            sta += currents[i-nminus:i+nplus+1]

    sta /= np.sum(spikes)
    
    time_window = np.arange(-nminus, nplus+1, 1)*dt*1e3

    return sta, time_window

sta, time_window = STA(current_downsampled, spikes_downsampled, dt)


# plot with plotly
fig = go.Figure()
fig.add_trace(go.Scatter(x=-time_window, y=sta, mode='lines', name='STA'))
fig.update_layout(
    title='STA',
    xaxis_title='Time (ms)',
    yaxis_title='Current (nA)',
    font=dict(
        family="Courier New, monospace",
        size=18,
        color="#7f7f7f"
    )
) 

fig.show()

```


With the STA plotted above, we can see the spike-triggerd average for an AELIF neuron. We can see that the currents patterns that causes spikes is initially close to zero, and then increases to a peak, and then decreases back to zero. This is because the neuron is initially at rest, and then the current causes the neuron to spike, and then the neuron returns to rest. This is a very simple example, but we can see that the STA can capture the general shape of the current pattern that causes spikes. Immediately after a spike the current goes below zero.x` 





## Spike-train statistics

:::{.callout-note collapse="true"}
# Fano factor and coefficient of variation

CV is defined as the standard deviation divided by the mean of a dataset, usually applied to ISI.


Fano factor is defined as the variance divided by the mean of a dataset, usually applied to spike counts.

$$
FF = \frac{\sigma^2}{\mu}
$$


:::


The Poisson distribution is a discrete PDF that describes the probability of a given number of events occurring in a fixed interval of time. The Poisson distribution is defined as:

$$
P(k) = \frac{\lambda^k e^{-\lambda}}{k!}
$$

where $\lambda$ is the mean number of events in the interval, if we set $\lambda=rT$, where $T$ is the length of the interval and $r$ is the firing rate. So $P(1)$ is the probability of one spike in the interval, etc. So the number of spikes $N$ can be described by a Poisson distribution with mean $rT$.

$$
N \sim P(rT)
$$

The probability of observing one spike in the interval is: $P(1) = (rT) ^ 1 e^{-rT} / 1! = rT e^{-rT}$, but if the time window is small then $P(1) \approx rT$.


## Statistical properties of the spike trains

### AELIF neuron with noise


```{python}

params.E_L = -70e-3
params.G_L = 10e-9
params.a = 2e-9
params.b = 0

params.tau_SRA = 150e-3

dt = 0.01e-3
times = np.arange(0, 10, dt)


mu, sigma = 0, 50e-9/np.sqrt(dt) 
currents = np.random.normal(mu, sigma, len(times))

print(f'Current max : {np.max(currents)}')
print(f'Currents min: {np.min(currents)}')

aelif = AELIFModel(

    neuron_parameters=params,
    times=times,
    I=currents,
)

aelif.simulate()

inter_spike_intervals = np.asarray(aelif.isi_array)

# remove outliers

inter_spike_intervals = inter_spike_intervals[inter_spike_intervals < 0.01]

print('set of ISI: ', set(inter_spike_intervals))

# plot the ISI with plotly
fig = go.Figure()
fig.add_trace(go.Histogram(x=inter_spike_intervals, name='ISI', nbinsx=25))
fig.update_layout(
    title='ISI',
    xaxis_title='Time (s)',
    yaxis_title='Count',
    font=dict(
        family="Courier New, monospace",
        size=18,
        color="#7f7f7f"
    )
)

fig.show()



```

The CV score for the ISI is a measure of how much the ISI varies. So for the simulation above, the CV score is :

```{python}
CV = np.std(inter_spike_intervals)/np.mean(inter_spike_intervals)
print(f'CV : {CV}')
```


```{python}

# find the number of spikes in 100 ms windows
def find_fano_factor(time_range, spike_locations):
    num_steps_per_window = int(time_range/dt)

    # check if we can split
    if len(spike_locations) % num_steps_per_window != 0:
        return

    # spit the 
    spike_locations = np.split(spike_locations, num_steps_per_window, axis=0)
    spike_locations = np.asarray(spike_locations)
    print(spike_locations.shape)

    # count the number of spikes in each window
    spike_counts = np.sum(spike_locations, axis=1)

    # calculate the Fano factor
    fano_factor = np.var(spike_counts)/np.mean(spike_counts)

    return fano_factor



spike_locations = np.asarray(aelif.spike_array)
fano_factor_b0 = find_fano_factor(100e-3, spike_locations)

```

Let's try with range from 10ms to 1s. 

```{python}

time_range_array = np.arange(10e-3, 1, 2e-3)
fano_factor_array = []

for time_range in time_range_array:

    fano_factor = find_fano_factor(time_range, spike_locations)
    if fano_factor is not None:
        fano_factor_array.append(fano_factor)

# plot with plotly
fig = go.Figure()
fig.add_trace(go.Scatter(x=time_range_array*1e3, y=fano_factor_array, mode='lines', name='Fano factor'))

fig.update_layout(
    title='Fano factor',
    xaxis_title='Time window (ms)',
    yaxis_title='Fano factor',
    font=dict(
        family="Courier New, monospace",
        size=18,
        color="#7f7f7f"
    )
)

fig.show()
```

As we increase the time window from 10ms to 1s, the Fano factor decreases. This is because the Fano factor is the variance divided by the mean, so as the mean increases, the variance decreases.

Now, what if we set the AELIF parameter to $b=1nA$? What happens to the Fano factor?

```{python}
params.b = 1e-9

aelif = AELIFModel(
    neuron_parameters=params,
    times=times,
    I=currents,
)

aelif.simulate()

# find the fano factor

spike_locations = np.asarray(aelif.spike_array)
fano_factor2 = find_fano_factor(100e-3, spike_locations)

print(f'The Fano factor with b=0 is: {fano_factor_b0}')
print(f'The Fano factor with b=1nA is: {fano_factor2}')

```

The variable $b$ for the AELIF neuron is how much the $I_{SRA}$ current increases after there is a spike. This current is hyperpolarising, so after a spike, the chance of firing for the next time step gets slower and slower. So the Fano factor decreases as $b$ increases. 


### ROC analysis tutorial







The receiver-operating characeteristic curvie (ROC) is a plot of the probability of true positive against the probability of false positives for different thresholds of a postive test result.


`Bimodality` is an indication of two different processes or distributions, one example is the pitch difference between male and female speakers.

If some trails initiate one process while another trail initialiates another, then the overall probability would be a combination of two distributions, or a bimodal distribution.


:::{.callout-note collapse="true"}
# z-score  
For a data point, the number of std away from the mean of the distribution
:::


```python
#import ray
#ray.init()

params.E_L = -70e-3
params.V_th = -50e-3
params.V_reset = -80e-3
params.Delta_th = 2e-3
params.G_L = 10e-9
params.C_m = 100e-12    
params.a = 2e-9
params.b = 0
params.tau_SRA = 150e-3

dt = 0.01 * 1e-3

times = np.arange(0, 0.5, dt)

num_trails = 1000

num_spikes_array_no_stim = []
num_spikes_array_stim = []

noise_sigma = 20e-12
mu, sigma = 0, noise_sigma/np.sqrt(dt)

current_no_stimulus = np.ones_like(times) * 0 + np.random.normal(mu, sigma, len(times))
current_stimulus = np.ones_like(times) * 0.1e-9 + np.random.normal(mu, sigma, len(times))

#for trail_id in range(num_trails):

#@ray.remote
def run_simulation(trail_id):

    aelif_no_stim = AELIFModel(
        times=times,
        neuron_parameters=params,
        I=current_no_stimulus,
        noise_sigma=noise_sigma,
    )
    aelif_no_stim.simulate()

    
    aelif_stim = AELIFModel(
        times=times,
        neuron_parameters=params,
        I=current_stimulus,
        noise_sigma=noise_sigma,
    )

    aelif_stim.simulate()

    #num_spikes_array_no_stim.append(np.sum(aelif_no_stim.spike_array))
    #num_spikes_array_stim.append(np.sum(aelif_stim.spike_array))

    no_spike = np.sum(aelif_no_stim.spike_array)
    spike = np.sum(aelif_stim.spike_array)

    return no_spike, spike

results = ray.get([run_simulation.remote(trail_id) for trail_id in range(num_trails)])

for result in results:
    num_spikes_array_no_stim.append(result[0])
    num_spikes_array_stim.append(result[1])


max_number_of_spikes = np.max(num_spikes_array_stim)

histogram_no_stim, bin_edges = np.histogram(num_spikes_array_no_stim, bins=np.arange(0, max_number_of_spikes+1))

histogram_stim, bin_edges = np.histogram(num_spikes_array_stim, bins=np.arange(0, max_number_of_spikes+1))


fig = go.Figure()
fig.add_trace(go.Scatter(x=bin_edges[:-1], y=histogram_no_stim, mode='lines', name='No stimulus'))
fig.add_trace(go.Scatter(x=bin_edges[:-1], y=histogram_stim, mode='lines', name='Stimulus'))

fig.update_layout(
    title='Histogram of number of spikes',
    xaxis_title='Number of spikes',
    yaxis_title='Probability',
    font=dict(
        family="Courier New, monospace",
        size=18,
        color="#7f7f7f"
    )
)

fig.show()
```

